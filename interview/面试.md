### 1 Python中的装饰器

Python中的装饰器其实也是一种函数， 它可以在不修改原函数代码情况下扩展原函数功能。装饰器函数与普通函数不同之处就在于

装饰器函数返回了一个函数对象，装饰器利用了闭包的原理来实现。主要用于日志插入，权限管理等等。

### 多进程和多线程

线程是最小的调度执行单元。如何调度进程和线程，完全由操作系统决定。

多进程和多线程的程序涉及到同步、数据共享的问题，编写起来更复杂。

总结一句话是“进程是操作系统分配资源的最小单元，线程是操作系统调度的最小单元”。

- 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位.

- 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中
必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.
一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行.

- 进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，
而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以
多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，
只能用线程，不能用进程。

多进程和多线程最大的不同在于，

**多进程**中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响.

**多线程**中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改.

因此，线程之间共享数据最大的危险在于多个线程同时改一个变量，把内容给改乱了。
Python多进程和多线程哪个快?

由于GIL的存在，很多人认为Python多进程编程更快，针对多核CPU，理论上来说也是采用多进程更能有效利用资源。网上很多人已做过比较，我直接告诉你结论吧。

    对CPU密集型代码(比如循环计算) - 多进程效率更高

    对IO密集型代码(比如文件操作，网络爬虫) - 多线程效率更高。

为什么是这样呢？其实也不难理解。对于IO密集型操作，大部分消耗时间其实是等待时间，在等待时间中CPU是不需要工作的，

那你在此期间提供双CPU资源也是利用不上的，相反对于CPU密集型代码，2个CPU干活肯定比一个CPU快很多。

那么为什么多线程会对IO密集型代码有用呢？这时因为python碰到等待会释放GIL供新的线程使用，实现了线程间的切换。

Python中多线程由于有GIL的影响， 导致在任意时间内只有一个线程在运行，所以Python的多线程在处理计算密集型任务上

效果反而不如单线程， 只有在处理IO密集型任务上多线程才能发挥实力，在等待IO过程中Python C源码会释放GIL， 最终

会导致线程在等待IO过程中会被暂停去执行其他的线程。python中GIL主要是由于历史原因导致Cpython虚拟机中的GIL难以

移除，同时GIL的存在保证了多线程之间数据完整性以及状态同步。


### 2 python协程

Python中协程最初使用yield来实现， 当程序运行到yield语句时就会将控制权交出来去执行其他的函数， 在Python3之前

只能通过原生yield、greenlet以及Gevent第三方库来实现协程， 在Python3 之后引入了yield from， yield from 用于

重构生成器。在Python3.5之后引用了async和await， 其作为yield from， yield的完美替身来实现协程。

就不同语言中面向并发设计的协程实现而言，Scala 与 Erlang 的 Actor 模型、Golang 中的 goroutine 都较 Python 更为成熟，

不同的协程使用通信来共享内存，优化了竞态、冲突、不一致性等问题。然而，根本的理念没有区别，都是在用户态通过事件循环

驱动实现调度。

生成器的进化

yield 关键字被加入到语法中，下一次从生成器中取值可以恢复到生成器上次 yield 执行的位置。

在 Python2.5 中生成器还加入了 send 方法，与 yield 搭配使用。

生成器不仅仅可以 yield 暂停到一个状态，还可以往它停止的位置通过 send 方法传入一个值改变其状态。

yield from 实现了在生成器内调用另外生成器的功能  在生成器中从其他生成器 yield 一个值，这样不同的生成器之间可以互相通信

每个协程都有独立的栈空间，即使它们是都工作在同一个线程中的

### 3 Python的垃圾回收机制以及内存管理

```
垃圾回收机制：
Python的垃圾回收机制以引用计数为主， 标记清除、分代回收为辅。

1 引用计数指：
Python在内部维护了针对每一个对象的引用计数，
当一个对象创建或者被引用时，其引用计数将加1，当一个对象被销毁或作用域失效时， 其引用计数将减1。只有对象的引用计数为0时，
这个对象将会被回收。引用计数的优点：简单、具有实时性。
缺点：对象循环引用时将永远不会被销毁。对于对象循环引用的状况

2 Python使用标记清除来解决，Python在内部实现了一个循环检测器， 不停的检测对象是否存在循环引用，如果两个对象互相循环引用
并且不包含其他第三者对象时， 其将会被收回。在Python参考手册中有写道：当一个对象无法获取时， 那么这个对象有可能被当成垃
圾销毁了。

3 Python将所有对象分成了三代， 对象存活时间越长就越晚被回收， 反之则越早被回收。


内存管理：内存池机制
http://images.cnitblog.com/blog/333250/201410/110017426714010.x-png

Python使用了内存池机制来管理内存，其内存以金字塔的形式对内存功能进行划分，
-1、-2层主要用于对操作系统进行操作， 
0层中是C的malloc,、free等等内存分配和释放函数。
1、2层是一个内存池， 当对象小于265K时将直接由这片内存池进行分配内存，否则将调用第0层中的C函数来分配内存，当小于265K的对象
被销毁时， 其内存也不会被销毁， 只是返回给了内存池以便二次利用。2层是对Python对象进行操作。


Python的内存机制以金字塔行，-1，-2层主要有操作系统进行操作，
第0层是C中的malloc，free等内存分配和释放函数进行操作；
第1层和第2层是内存池，有Python的接口函数PyMem_Malloc函数实现，当对象小于256K时有该层直接分配内存；
第3层是最上层，也就是我们对Python对象的直接操作；

在 C 中如果频繁的调用 malloc 与 free 时,是会产生性能问题的.再加上频繁的分配与释放小块的内存会产生内存碎片. 
Python 在这里主要干的工作有:
如果请求分配的内存在1~256字节之间就使用自己的内存管理系统,否则直接使用 malloc.
这里还是会调用 malloc 分配内存,但每次会分配一块大小为256k的大块内存.
经由内存池登记的内存到最后还是会回收到内存池,并不会调用 C 的 free 释放掉.以便下次使用
```
### 4 IaaS PaaS SaaS

IaaS 是云服务的最底层，提供硬件基础设施部署服务，主要提供实体或虚拟的计算、存储和网络等资源。它与 PaaS 的区别是，用户需

要自己控制底层，实现基础设施的使用逻辑。

PaaS 提供软件部署平台（runtime），是云计算应用程序运行环境，提供应用程序部署与管理服务，抽象掉了硬件和操作系统细节，可以

无缝地扩展（scaling）。开发者只需要关注自己的业务逻辑，不需要关注底层

SaaS 是软件的开发、管理、部署都交给第三方，不需要关心技术问题，可以拿来即用。普通用户接触到的互联网服务，几乎都是 SaaS


### os、sys模块不同

os、sys模块不同，并列举常用的模块方法

os: 提供了对使用操作系统函数的高度封装
sys: 提供由解释器访问或者维护的变量以及与解释器交互的一些函数

os模块只负责程序与操作系统交互， 提供了访问操作系统底层的接口封装。
sys模块负责程序与解释器交互， 提供了一系列的函数用于操控Python运行的环境设置。
https://zhuanlan.zhihu.com/p/38226619

### 切片是浅拷贝

Python中拷贝分为深拷贝、浅拷贝。浅拷贝只拷贝父级对象， 不会拷贝对象内部的子对象，使用copy模块中的copy。深拷贝则会完全拷贝父对象以及子对象， 使用copy模块中的deepcopy。
